# -*- coding: utf-8 -*-
"""Knn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D3Hn2KsQp0dydK9TxQUAQe45E1agt-B7
"""

#importar las librerias
import pandas as pd
import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

#cargamos dataset de cancer_breast
cancer_b = datasets.load_breast_cancer()

#creamos dataframe
df_can = pd.DataFrame(cancer_b.data, columns=cancer_b.feature_names)
df_can.head()

df_can['Target'] = cancer_b.target
df_can.head()

df_can['Target_name'] = df_can.Target.apply(lambda x: cancer_b.target_names[x])
df_can.head()

X = df_can.drop(['Target', 'Target_name'], axis=1)
y = df_can['Target']

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

knn = KNeighborsClassifier(n_neighbors=9, metric='euclidean')

knn.fit(x_train, y_train)

y_pred = knn.predict(x_test)
y_pred

acc = knn.score(x_test, y_test)
acc

confusion_matrix(y_test, y_pred)

#se refiere a:
#Verdaderos positivos | Falsos negativos
#Falsos positivos.    | verdaderos negativos

#lo ideal es los falsos positivos y falsos negativos sean 0

print(classification_report(y_test, y_pred))

# mejor valor para n_neighbors
error_rate = []
for i in range(1,10):
  knn = KNeighborsClassifier(n_neighbors=i)
  knn.fit(x_train, y_train)
  pred_i = knn.predict(x_test)
  error_rate.append(np.mean(pred_i != y_test))

plt.figure(figsize=(10,6))
plt.plot(range(1,10), error_rate, color='blue', linestyle='dashed',
         marker='o',markerfacecolor='red',markersize=10)
plt.title('Error rate vs N_Neighbors value')
plt.xlabel('n_nneighbors')
plt.ylabel('error_rate')
print('Minumun error: ', min(error_rate), 'at n_neighbors', error_rate.index(min(error_rate))+1)